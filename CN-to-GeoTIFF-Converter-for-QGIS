#!/usr/bin/env python3
# ...existing code...
import os
import sys
import glob
import argparse
import pandas as pd
import rasterio as rio
from rasterio.transform import from_origin
import xarray as xr
import numpy as np

def print_err(msg):
    print(f"ERROR: {msg}", file=sys.stderr)


def convert_nc_to_tifs(in_dir, out_dir, var_name=None):
    """Convert .nc files in in_dir to GeoTIFFs in out_dir.

    Writes one GeoTIFF per file or one per time slice if a time dimension exists.
    Assumes lat/lon coordinates are present and writes in EPSG:4326.
    """
    os.makedirs(out_dir, exist_ok=True)
    nc_files = sorted(glob.glob(os.path.join(in_dir, '*.nc')))
    if not nc_files:
        print_err(f"No .nc files found in {in_dir}")
        return

    for nc in nc_files:
        print(f"Converting: {nc}")
        try:
            ds = xr.open_dataset(nc)
        except Exception as e:
            print_err(f"Failed to open {nc}: {e}")
            continue

        # choose variable
        if var_name:
            if var_name not in ds:
                print_err(f"Variable '{var_name}' not found in {nc}; available: {list(ds.data_vars.keys())}")
                ds.close()
                continue
            da = ds[var_name]
        else:
            vars_available = [v for v in ds.data_vars]
            if not vars_available:
                print_err(f"No data variables in {nc}")
                ds.close()
                continue
            da = ds[vars_available[0]]
            var_name = da.name

        # find lat/lon coord names
        lat_names = ['lat', 'latitude', 'y']
        lon_names = ['lon', 'longitude', 'x']
        lat_name = next((n for n in lat_names if n in ds.coords), None)
        lon_name = next((n for n in lon_names if n in ds.coords), None)
        if lat_name is None or lon_name is None:
            print_err(f"Could not find lat/lon coords in {nc}; coords: {list(ds.coords.keys())}")
            ds.close()
            continue

        lat = ds[lat_name].values
        lon = ds[lon_name].values

        # determine pixel resolution and transform
        if lon.size > 1:
            xres = float(abs(lon[1] - lon[0]))
        else:
            xres = 1.0
        if lat.size > 1:
            yres = float(abs(lat[1] - lat[0]))
        else:
            yres = 1.0

        west = float(lon.min())
        north = float(lat.max())
        transform = from_origin(west, north, xres, yres)

        # determine nodata
        nodata = None
        if hasattr(da, '_FillValue'):
            nodata = da._FillValue
        elif '_FillValue' in da.attrs:
            nodata = da.attrs.get('_FillValue')
        elif 'missing_value' in da.attrs:
            nodata = da.attrs.get('missing_value')

        basename = os.path.splitext(os.path.basename(nc))[0]

        def _write_tif(array2d, outname):
            outpath = os.path.join(out_dir, outname)
            dtype = np.float32
            # If lat is ascending (south->north), flip to top-to-bottom
            try:
                lat0 = float(lat[0])
                latlast = float(lat[-1])
                if lat0 < latlast:
                    array2d = np.flipud(array2d)
            except Exception:
                pass

            height, width = array2d.shape
            write_kwargs = dict(driver='GTiff', height=height, width=width, count=1,
                                dtype=dtype, crs='EPSG:4326', transform=transform)
            if nodata is not None:
                write_kwargs['nodata'] = nodata
            try:
                with rio.open(outpath, 'w', **write_kwargs) as dst:
                    dst.write(array2d.astype(dtype), 1)
                print(f"Wrote: {outpath}")
            except Exception as e:
                print_err(f"Failed to write {outpath}: {e}")

        # handle time dimension if present
        if 'time' in da.dims:
            times = da['time'].values
            for idx, t in enumerate(times):
                try:
                    slice_da = da.isel(time=idx)
                    arr = np.array(slice_da.values)
                    if arr.ndim != 2:
                        arr = np.squeeze(arr)
                    try:
                        tstamp = pd.to_datetime(t).strftime('%Y%m%d')
                    except Exception:
                        tstamp = str(idx)
                    outname = f"{basename}_{var_name}_{tstamp}.tif"
                    _write_tif(arr, outname)
                except Exception as e:
                    print_err(f"Error processing time index {idx} in {nc}: {e}")
        else:
            try:
                arr = np.array(da.values)
                if arr.ndim != 2:
                    arr = np.squeeze(arr)
                outname = f"{basename}_{var_name}.tif"
                _write_tif(arr, outname)
            except Exception as e:
                print_err(f"Error writing data from {nc}: {e}")

        ds.close()

# Command-line arguments
parser = argparse.ArgumentParser(description='Upload GeoTIFFs to GCS and Earth Engine')
parser.add_argument('dataset', nargs='?', default='sif', help="Dataset key (default: 'sif')")
parser.add_argument('--run', action='store_true', help='Actually run earthengine upload (otherwise dry-run)')
parser.add_argument('--upload-gcs', dest='upload_gcs', action='store_true', help='Copy local TIFFs to GCS before uploading to EE')
parser.add_argument('--bucket', dest='bucket', default=None, help="Override GCS bucket path (format: bucket/path or bucket). Overrides gc_bucket_dict in the script")
parser.add_argument('--gcp-project', dest='gcp_project', default=None, help='Optional GCP project to initialize ee with')
parser.add_argument('--limit', dest='limit', type=int, default=0, help='Limit processing to first N files (0 = all)')
parser.add_argument('--use-legacy', dest='use_legacy', action='store_true', help='Use legacy user assets path (users/<name>/...) instead of project assets')
parser.add_argument('--convert-nc', dest='convert_nc', action='store_true', help='Convert .nc files to GeoTIFFs and exit')
parser.add_argument('--nc-input', dest='nc_input', default=r"D:\Lewis\Global phenology maping\Global_SIF_OCO2_MODIS_1863\data", help='Input folder containing .nc files')
parser.add_argument('--nc-output', dest='nc_output', default=r"D:\Lewis\Global phenology maping\output_phen\sif_to_tiff", help='Output folder for GeoTIFFs')
parser.add_argument('--nc-var', dest='nc_var', default=None, help='Variable name in the netCDF to convert (if omitted, first data var is used)')
args = parser.parse_args()

# If requested, run NetCDF -> GeoTIFF conversion and exit early (skip uploads)
if args.convert_nc:
    in_dir = args.nc_input
    out_dir = args.nc_output
    var = args.nc_var
    print(f"Running NetCDF -> GeoTIFF conversion: {in_dir} -> {out_dir} (var={var})")
    convert_nc_to_tifs(in_dir, out_dir, var)
    print("Conversion finished. Exiting.")
    sys.exit(0)

print("Conversion script ready. Use --convert-nc to run NetCDF -> GeoTIFF conversion.")
